# Algorithm and Data Structure Implementations

1. **Linear Search (Easy):** Scan each element of a list/array sequentially to find a target value. Data structures: array or Python list. OOP design: implement as a method in a `Searcher` class or similar, encapsulating the search logic. (Single Responsibility Principle: each search algorithm in its own class or static method.) 

2. **Binary Search (Easy):** Repeatedly divide a *sorted* array in half to locate a target, cutting the search space in half each step. Data: sorted array/list. OOP: could be a static method of a `Searcher` base class or part of a `SearchStrategy` interface. Encapsulate sorted-data requirement internally; e.g., raise an error if the list is not sorted. 

3. **Stack (Easy):** LIFO (last-in-first-out) data structure supporting push/pop; typically implemented with a list or linked nodes. Data: linked nodes or underlying list/deque. OOP: model as a `Stack` class with private storage; methods `push()`, `pop()`, `peek()`. Enforce encapsulation by hiding internal container; use inheritance only if extending stack behavior (e.g., adding capacity limit). 

4. **Queue (Easy):** FIFO (first-in-first-out) data structure supporting enqueue/dequeue. Data: linked nodes or deque. OOP: implement a `Queue` class (or use composition with `collections.deque`), providing `enqueue()`/`dequeue()` methods. Hide implementation details, e.g., using a private deque member. 

5. **Linked List (Easy):** A sequence of nodes where each node holds data and a pointer to the next node. Data: Node class with `data` and `next`. OOP: Create `Node` and `LinkedList` classes. Encapsulate head pointer and list operations (insert/delete). Use composition (list holds Node objects) and keep the Node class private if possible. Follow SRP: LinkedList class manages structure, Node just holds value. 

6. **Binary Tree Traversals (Easy):** Recursive visits of all nodes in a binary tree (in-order, pre-order, post-order). Data: binary tree (nodes with left/right pointers). OOP: define a `TreeNode` class and traversal methods (e.g., `inorder(self)`). Encapsulate recursion within the `Tree` or `TreeNode` class. For level-order (BFS), use a queue internally. Implement as instance methods or via an Iterator pattern, hiding traversal details. 

7. **Binary Search Tree (BST) (Intermediate):** A tree where left < root < right at each node, supporting efficient search/insert/delete (O(log n) on average). Data: Node with `left`/`right`. OOP: `BST` class with methods `insert()`, `find()`, etc. Use the private Node class. Each operation is a separate method. Apply encapsulation: tree balancing or persistence can be added later without changing the interface (Open/Closed). 

8. **Bubble Sort (Easy):** Repeatedly swap adjacent out-of-order elements until the list is sorted. Data: array/list. OOP: Implement as a subclass (e.g., `BubbleSort`) of a generic `Sorter` interface or base class. Use the Strategy pattern so that sorting algorithms are interchangeable. Each sort class has a `sort(self, array)` method. Bubble Sort’s class would encapsulate the simple inner/outer loop logic. 

9. **Selection Sort (Easy):** Repeatedly find the minimum (or maximum) element from the unsorted portion and swap it into place. Data: array/list. OOP: Like Bubble, implement as `SelectionSort` subclass of `Sorter`. Each algorithm class follows the single responsibility principle (only implements one sort). You might have a `SortContext` that accepts different `Sorter` strategies. 

10. **Insertion Sort (Easy):** Build a sorted array incrementally by inserting each element into its correct position. Data: array/list. OOP: `InsertionSort` class with a `sort()` method. The sorted-part vs unsorted-part distinction is managed internally. The `Sorter` base class can define an interface so clients depend only on that interface (Dependency Inversion). 

11. **Merge Sort (Intermediate):** Divide-and-conquer sort: recursively split array in half, sort each, then merge. Data: array (recursion uses extra arrays or temporary lists). OOP: `MergeSort` class. Could implement the Template Method pattern in a base class: define a `sort()` skeleton that calls abstract `divide()` and `merge()`. Ensure recursion details are encapsulated. Use composition: MergeSort may use an internal buffer or helper class for merging. 

12. **Quick Sort (Intermediate):** Divide-and-conquer sort: choose a pivot, partition elements < and ≥ pivot, then recursively sort partitions. Data: array. OOP: `QuickSort` class. In the OOP library, implement the partition logic as a helper method. Possibly use the Strategy pattern to choose the pivot selection strategy. Respect encapsulation: the class holds no state (static-like method) or minimal state. 

13. **Heap Sort (Intermediate):** Build a binary heap from the array, then repeatedly extract the max and rebuild the heap to sort. Data uses an implicit binary heap (array-based tree). OOP: `HeapSort` class. May also implement a separate `MaxHeap` class (node-based or array-based) for clarity, then use it for sorting. Demonstrate composition by using a `Heap` data structure inside the sort class. 

14. **Counting Sort (Intermediate):** Non-comparison sort for small integer ranges: count frequency of each value, then compute positions. Data: input array and auxiliary count array. OOP: `CountingSort` class. Encapsulate range logic; could parameterize by range (min, max). Use methods to build a count and output a sorted array. (Not based on comparisons, but still fits into a `Sorter` interface.) 

15. **Radix Sort (Advanced):** Linear-time non-comparison sort by processing individual digits or letters, distributing elements into buckets by each digit. Data: array of numbers or strings. OOP: `RadixSort` class. Use the composition of `CountingSort` internally for each digit pass. Use multiple passes: e.g., loop over digit positions. The class encapsulates how keys are extracted and buckets are processed, adhering to SRP. 

16. **Graph (Adjacency List) (Intermediate):** A graph represented by a mapping (dictionary) from vertices to lists of neighbor vertices. For example, a `Graph` class contains a dict of `Vertex` objects, each with its own adjacency list. Data: dictionary/map of `Vertex` instances. OOP: Define `Graph` and `Vertex` classes. Use composition: `Graph` holds `Vertex` objects; `Vertex` holds edges. Encapsulate adjacency logic inside methods (e.g., `add_edge()`). Implement iteration over vertices by defining `__iter__` in `Graph`. Follow Single Responsibility: Graph class manages vertices/edges, and Vertex holds its neighbors. 

17. **Breadth-First Search (BFS) (Intermediate):** Graph traversal visiting neighbors level by level using a queue. Data: Graph (as above), and a queue. OOP: A method like `bfs(start_vertex)` in the `Graph` class or a separate `GraphSearch` class. Use a queue data structure internally. Encapsulate the visited set within the method. If `Graph` provides an iterator or neighbor accessor, BFS is implemented cleanly without exposing internal lists. BFS class or method adheres to SRP and can utilize an injected queue (dependency inversion) if desired. 

18. **Depth-First Search (DFS) (Intermediate):** Graph traversal going deep via recursion or a stack. Data: Graph and either a recursion stack or an explicit stack. OOP: `dfs(start)` method in `Graph` or `GraphSearch` class. Can be implemented recursively or with a private stack variable. Use encapsulation to hide recursion logic. A clean design is to write a public `dfs()` that initializes data structures, and a private helper `_dfs_rec()` that does recursion. Supports solutions such as path finding by storing parents, etc. 

19. **Topological Sort (Intermediate):** Linear ordering of a DAG’s vertices so that for every directed edge u→v, u comes before v. Data: directed acyclic graph (Graph). OOP: `topological_sort()` method in `Graph` or a `GraphAlgorithms` class. Can be implemented via DFS or Kahn’s algorithm (in-degree queue). Use internal data (temporary in-degree count or recursion stack). The method hides details from the client. The Graph class’s adjacency lists are used internally to compute order. Demonstrates SRP: separate method for this algorithm. 

20. **Dijkstra’s Algorithm (Intermediate):** Finds shortest paths from a source in a weighted graph with non-negative edges (single-source shortest path). Data: Graph (adjacency list with weights) plus a min-priority queue (binary heap). OOP: `dijkstra(source)` method in `Graph` or separate `PathFinder` class. Use a `PriorityQueue` (heapq) internally. Encapsulate the distance map and visited set. Could define a `GraphWeighted` subclass or flag to allow weighted edges. Keep algorithm logic inside one class, ensuring maintainability. (E.g., Graph class has a method but keeps weights internal; or use a separate Dijkstra class with a `Graph` instance via composition.) 

21. **Prim’s Minimum Spanning Tree (Intermediate):** Greedily builds an MST by starting at a root and adding the cheapest edge that connects the tree to a new vertex. Data: weighted Graph and a min-heap (priority queue). OOP: `prim(start)` method. Could be in `Graph` or an `MST` class. Internally maintain a priority queue of edges. Use Graph’s adjacency lists. Following SRP, the Graph data structure remains separate from Prim’s algorithm logic. Possibly implement an `Edge` class. Graph holds vertices, while Prim’s algorithm class holds and processes edges, using composition. 

22. **Kruskal’s Minimum Spanning Tree (Intermediate):** Greedy MST by sorting all edges by weight and adding them if they don’t form a cycle (using disjoint-set). Data: edge list of Graph, Union-Find structure. OOP: `Kruskal ()` method in an `MST` or `Graph` class. First, get edges sorted (use a comparator or lambda). Use a `DisjointSet` class for cycle checks. Maintain encapsulation: graph stores edges, Kruskal’s method uses them, but does not modify the Graph permanently. Follow OOP: separate MST logic from Graph, inject `DisjointSet` via composition. 

23. **Disjoint Set (Union-Find) (Intermediate):** Data structure for tracking disjoint sets, supporting `find(x)` and `union(x,y)`. Data: array/dict of parent pointers and ranks. OOP: `DisjointSet` class with methods `find()` and `union()`. Encapsulate the parent and rank arrays internally. Use path compression and union-by-rank within methods. Graph algorithms like Kruskal use this class by composition. This follows SRP: disjoint-set logic in its own class. 

24. **Activity Selection (Greedy) (Intermediate):** Select the maximum number of non-overlapping activities given start/finish times by always picking the next activity with the earliest finish time. Data: list of intervals. OOP: `ActivitySelector` class or method. Sort activities (using Sorter classes) by finish time, then iterate greedily. Keep scheduling state (lastFinish) in the instance. Encapsulate intervals and sorting inside the class. This class could reuse a `Sorter` strategy for sorting by finish time. 

25. **Fractional Knapsack (Greedy) (Intermediate):** Given items with weight/value and a capacity, fill the bag for max value by taking fractions of the highest value/weight first. Data: list of items (value, weight). OOP: `KnapsackGreedy` class. Compute ratio, sort items (using composition of a Sorter), then iterate, taking items or fractions. Encapsulate the greedy loop. Each item might be an object with its own data. The class is open for new item types (Open/Closed). 

26. **Huffman Coding (Greedy) (Intermediate):** Build an optimal prefix tree for data compression by repeatedly merging the two lowest-frequency nodes. Data: min-heap of tree nodes. OOP: `HuffmanCoder` class. Use a `PriorityQueue` of `TreeNode` objects. Each node holds a character and frequency. Greedily combine the two smallest nodes into a parent node. Encapsulation: `HuffmanCoder.build_tree()` method hides the merge process; the resulting `Trie` (prefix tree) can be a separate class. Follows SRP: coding logic separate from I/O. 

27. **Fibonacci with DP (Easy):** Compute the nth Fibonacci number using memoization to avoid exponential recursion. (Classic DP example.) Data: use a cache (dict) and simple recursion/iteration. OOP: `Fibonacci` class with a method `compute(n)` that uses an internal dictionary or list for memo. Encapsulate the cache in the class. This demonstrates DP by storing intermediate results in the instance state, adhering to encapsulation, and making the method efficient. (One could also implement via `@lru_cache` in Python for brevity.) 

28. **0/1 Knapsack (Intermediate):** Maximize total value under weight capacity (without fractions) by DP over items and weights. Data: 2D DP table of size n×W. OOP: `KnapsackDP` class. Use methods to build the DP matrix. Encapsulate the DP table (as a list of lists) internally. Could offer `solve(weights, values, W)` returning the max value. By separating the DP logic in its own class, we respect SRP. One could use either a top-down memo or a bottom-up table. 

29. **Longest Common Subsequence (LCS) (Advanced):** Given two strings, find the length of the longest subsequence present in both. Data: 2D DP table of size (len1+1)×(len2+1). OOP: `LCS` class with `compute(str1, str2)` method. Encapsulate the DP table. Could use memoization in recursion as well. Follow OOP: hide the table and recursion details inside the class. Good design is to separate “compare characters” logic from DP update (for clarity). Use Single Responsibility: the class only solves LCS. 

30. **Longest Increasing Subsequence (LIS) (Advanced):** Find the longest strictly increasing subsequence in an array. Data: use DP array or tails with binary search for O(n log n). OOP: `LIS` class. For the DP solution, maintain an array `d[i]` inside the class. For an efficient solution, maintain a list of tail values. Encapsulation: class method `length(sequence)` that handles logic. This class can be extended (Open/Closed) to use different algorithms (DP vs patience sorting) by strategy, without changing the interface. 

31. **Subset Generation (Backtracking, Easy):** Generate all subsets (the power set) of a set via recursion. Data: original list/array and a temporary list for building subsets. OOP: `SubsetFinder` class. Use a method `generate(nums)` returning a list of subsets. Encapsulate recursion in a private method. Use backtracking pattern: include or exclude each element. Class holds the current subset state and final results. This respects SRP by confining subset logic to one class. 

32. **Permutation Generation (Backtracking, Intermediate):** Generate all permutations of a list by swapping elements recursively. Data: a list and an index pointer. OOP: `PermutationFinder` class with `permute(array)` method. Internally, use recursion and backtracking. The class may hold a result list as an attribute. The swap and recursion are encapsulated, and the public API simply returns all permutations. This class does one job (SRP) and can be reused in other modules. 

33. **N-Queens (Backtracking, Advanced):** Place N queens on an N×N chessboard so no two attack each other. Data: 2D board (array) or lists of column/diagonal occupancy. OOP: `NQueensSolver` class. Use methods like `solve(n)` that internally call a recursive `place(row)` function with backtracking. Encapsulate the board and the placed-queen state. Follow OOP: separate board representation (maybe a `Board` class) from solving logic. Apply backtracking pattern: try placing in each column and recurse, backtrack on conflict. 

34. **Sudoku Solver (Backtracking, Expert):** Fill a 9×9 grid so each row/col/3×3 block has 1–9, using backtracking. Data: 2D array of ints. OOP: `SudokuSolver` class. Method `solve(board)` uses recursive backtracking: fill empty cell, check validity, recurse, and backtrack. Encapsulate board and constraint checks inside the class. Single Responsibility: This class only solves Sudoku (not UI or I/O). Could use a helper `Board` class for checking rows/cols/blocks if desired. 

35. **Trie (Prefix Tree) (Intermediate):** Tree structure for storing strings with efficient prefix lookup. Data: nodes with an array/dict of child pointers (one per character) and a flag for word end. OOP: `TrieNode` and `Trie` classes. `Trie` provides `insert()`, `search()`, `starts_with()` methods. Use composition: `Trie` holds a root `TrieNode`. Hide the node structure (private). Encapsulate character-index logic inside nodes. SOLID: `Trie` class has a single responsibility for word storage and lookup. 

36. **AVL Tree (Advanced):** A self-balancing BST where heights of subtrees differ by ≤1. Data: BST nodes with height attribute. OOP: `AVLTree` class (subclass or variant of BST). Methods `insert()` and `delete()` automatically perform rotations to rebalance. Encapsulate rotations (`_rotate_left`, `_rotate_right`) and balancing logic internally. The BST property and balance factor are maintained by the class. Clients use `insert(value)` without worrying about balancing details (Encapsulation, Open/Closed). 

37. **Red-Black Tree (Expert):** A self-balancing BST with node colors and strict properties to guarantee O(log n) operations. Data: BST nodes with an extra color bit. OOP: `RedBlackTree` class (could subclass a general BST). Implement `insert()`/`delete()` with color-fixing logic. Encapsulate color rules and rotations inside the class. The outside interface remains `insert(value)`, etc. This follows SOLID by hiding complex balancing (Single Responsibility of tree structure management).